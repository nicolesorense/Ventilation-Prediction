# -*- coding: utf-8 -*-
"""ventilation_deep_learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jc5cFwH2Gt5W1Jd0Ui1eOnvRJNX6SO1X

# Ventilation Prediction: Multimodal Deep Learning

This notebook implements a multimodal deep learning model to predict the need for mechanical ventilation in ICU patients using the MIMIC-IV dataset. It combines:
- Time-series data (vital signs, lab results) processed with an LSTM.
- Clinical notes processed with ClinicalBERT.
- Fusion layers to integrate both modalities for binary classification (ventilation: 0/1).

## Prerequisites
- **Python**: 3.8+
- **Dependencies**: Install via:
```bash
pip install torch transformers pandas numpy scikit-learn imblearn matplotlib tqdm
```
- **Data**: Preprocessed MIMIC-IV data from `ventilation_dl_preprocessing.ipynb` (see [PhysioNet](https://physionet.org/content/mimiciv/2.2/)).
- **Hardware**: GPU recommended (e.g., NVIDIA T4).

## Data Requirements
The notebook expects preprocessed data in `data/wrangled/`:
- **Time-series data**: `.npy` files (`train_combined_time_series_data.npy`, `val_combined_time_series_data.npy`, `test_combined_time_series_data.npy`) with shape `(samples, timesteps, features)`.
- **Ventilation labels**: `.npy` files (`train_vent_labels.npy`, `val_vent_labels.npy`, `test_vent_labels.npy`) with binary labels (0/1).
- **Clinical notes**: `.csv` files (`train_vent_notes.csv`, `val_vent_notes.csv`, `test_vent_notes.csv`) with a `Notes` column.
**Warning**: These files contain MIMIC-IV-derived data, including sensitive clinical notes. Do not share publicly. Ensure compliance with the MIMIC-IV Data Use Agreement (DUA).

## Usage
1. Clone the repository: `git clone https://github.com/nicolesorense/Ventilation-Prediction`
2. Install dependencies: `pip install -r requirements.txt`
3. Place preprocessed data in `data/wrangled/` (see `ventilation_dl_preprocessing.ipynb`).
4. Run the notebook cells sequentially.
"""

import os
import torch
import collections
import pandas as pd
import numpy as np
import torch.nn as nn
import matplotlib.pyplot as plt
from tqdm import tqdm
from sklearn.model_selection import train_test_split
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    precision_recall_curve,
    precision_recall_fscore_support,
    roc_curve,
    auc,
    average_precision_score,
    f1_score,
    accuracy_score,
    roc_auc_score,
    precision_score
)
from imblearn.over_sampling import SMOTE
from transformers import AutoTokenizer, AutoModel
from torch.utils.data import DataLoader, Dataset

"""## Data Loading
Loads preprocessed time-series data, ventilation labels, and clinical notes from `data/wrangled/`
**Warning**: These files contain MIMIC-IV-derived data, including sensitive clinical notes. Do not share publicly. Ensure compliance with the MIMIC-IV DUA.
"""

# Define data directory
data_dir = 'data/wrangled/'

# Load time-series data
print('Warning: The input .npy files contain MIMIC-IV-derived data. Do not share publicly.')
try:
    train_ts = np.load(os.path.join(data_dir, 'train_combined_time_series_data.npy'), allow_pickle=True)
    val_ts = np.load(os.path.join(data_dir, 'val_combined_time_series_data.npy'), allow_pickle=True)
    test_ts = np.load(os.path.join(data_dir, 'test_combined_time_series_data.npy'), allow_pickle=True)
except FileNotFoundError as e:
    print(f'Error: .npy file not found in {data_dir}: {e}')
    raise
# Load ventilation labels
try:
    train_vent_labels = np.load(os.path.join(data_dir, 'train_vent_labels.npy'), allow_pickle=True)
    val_vent_labels = np.load(os.path.join(data_dir, 'val_vent_labels.npy'), allow_pickle=True)
    test_vent_labels = np.load(os.path.join(data_dir, 'test_vent_labels.npy'), allow_pickle=True)
except FileNotFoundError as e:
    print(f'Error: .npy file not found in {data_dir}: {e}')
    raise

# Load clinical notes
try:
    train_notes_data = pd.read_csv(os.path.join(data_dir, 'train_vent_notes.csv'))
    val_notes_data = pd.read_csv(os.path.join(data_dir, 'val_vent_notes.csv'))
    test_notes_data = pd.read_csv(os.path.join(data_dir, 'test_vent_notes.csv'))
except FileNotFoundError as e:
    print(f'Error: CSV file not found in {data_dir}: {e}')
    raise

# Handle missing notes
train_notes_data['Notes'] = train_notes_data['Notes'].fillna('')
val_notes_data['Notes'] = val_notes_data['Notes'].fillna('')
test_notes_data['Notes'] = test_notes_data['Notes'].fillna('')

# Set seed for determinism
def set_seed(seed):
    import random
    import numpy as np
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

seed = 42
set_seed(seed)

# Change ts data to tensor
train_ts_tensor = torch.tensor(train_ts, dtype=torch.float32)
val_ts_tensor = torch.tensor(val_ts, dtype=torch.float32)
test_ts_tensor = torch.tensor(test_ts, dtype=torch.float32)

# Function to load clinicalBERT
def load_clinicalbert():
  model_name = "emilyalsentzer/Bio_ClinicalBERT"
  tokenizer = AutoTokenizer.from_pretrained(model_name)
  model = AutoModel.from_pretrained(model_name)
  return tokenizer, model

# Function to tokenize clinical notes
def tokenize_clinical_notes(clinical_notes, tokenizer, max_length=128):
  tokenized = tokenizer(
      clinical_notes,
      max_length=max_length,
      padding='max_length',
      truncation=True,
      return_tensors="pt"
  )
  return tokenized

# Load clinicalBERT and its tokenizer
tokenizer, clinicalbert = load_clinicalbert()

# Tokenize clinical notes
train_tokenized_inputs = tokenize_clinical_notes(train_notes_data['Notes'].tolist(), tokenizer)
val_tokenized_inputs = tokenize_clinical_notes(val_notes_data['Notes'].tolist(), tokenizer)
test_tokenized_inputs = tokenize_clinical_notes(test_notes_data['Notes'].tolist(), tokenizer)

class MultiModalDataset(Dataset):
  def __init__(self, time_series_data, tokenized_data, labels):
    self.time_series_data = time_series_data
    self.input_ids = tokenized_data['input_ids'] # ids of the tokens
    self.attention_mask = tokenized_data['attention_mask']
    self.labels = labels

  def __len__(self):
    return len(self.time_series_data)

  def __getitem__(self, idx):
    return {
        'time_series': self.time_series_data[idx],
        'input_ids': self.input_ids[idx],
        'attention_mask': self.attention_mask[idx],
        'labels': self.labels[idx]
    }

# Create a dataset and dataloader
g = torch.Generator()
seed = 42
g.manual_seed(seed)
train_dataset = MultiModalDataset(train_ts, train_tokenized_inputs, train_vent_labels)
train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, generator=g)
val_dataset = MultiModalDataset(val_ts, val_tokenized_inputs, val_vent_labels)
val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True, generator=g)
test_dataset = MultiModalDataset(test_ts, val_tokenized_inputs, test_vent_labels)
test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True, generator=g)

class MultimodalModel(nn.Module):
    def __init__(self, lstm_input_size, lstm_hidden_size, lstm_num_layers, clinicalbert_model):
        super(MultimodalModel, self).__init__()

        # Masking value for time series
        self.mask_value = -1.0

        # LSTM for time series data
        self.lstm = nn.LSTM(
            input_size=lstm_input_size,
            hidden_size=lstm_hidden_size,
            num_layers=lstm_num_layers,
            batch_first=True
        )
        self.lstm_norm = nn.LayerNorm(lstm_hidden_size)
        self.dropout_lstm = nn.Dropout(0.3)

        # ClinicalBERT for text data
        self.clinicalbert = clinicalbert_model
        self.bert_norm = nn.LayerNorm(768)  # ClinicalBERT's hidden size

        # Fusion layers
        self.dropout_fusion = nn.Dropout(0.3)
        self.fc_fusion = nn.Linear(lstm_hidden_size + 768, 128)
        self.leaky_relu = nn.LeakyReLU(0.1)
        self.fc_output = nn.Linear(128, 1)

        # Initialize weights to improve gradient flow
        self._init_weights()

    def _init_weights(self):
        """Initialize weights to prevent vanishing gradients."""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
            elif isinstance(m, nn.LSTM):
                for name, param in m.named_parameters():
                    if 'weight' in name:
                        nn.init.xavier_uniform_(param)
                    elif 'bias' in name:
                        nn.init.zeros_(param)

    def forward(self, time_series_data, input_ids, attention_mask):
        # Masking for LSTM input
        mask = (time_series_data != self.mask_value).float()
        time_series_data = time_series_data * mask

        # LSTM branch
        lstm_out, _ = self.lstm(time_series_data)
        lstm_out = lstm_out[:, -1, :]  # Take the last hidden state
        lstm_out = self.lstm_norm(lstm_out)
        lstm_out = self.dropout_lstm(lstm_out)

        # ClinicalBERT branch
        bert_out = self.clinicalbert(input_ids=input_ids, attention_mask=attention_mask)
        bert_pooled = bert_out.last_hidden_state[:, 0, :]  # CLS token embedding
        bert_pooled = self.bert_norm(bert_pooled)
        # Weight BERT output by non-empty notes to handle 72.6% empty notes
        non_empty = (attention_mask.sum(dim=1) > 1).float().unsqueeze(1)
        bert_pooled = bert_pooled * non_empty

        # Fusion
        combined = torch.cat((lstm_out, bert_pooled), dim=1)
        combined = self.dropout_fusion(combined)
        fused = self.fc_fusion(combined)
        fused = self.leaky_relu(fused)
        output = self.fc_output(fused)

        return output

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Hyperparameters
lstm_input_size = train_ts_tensor.size(2)
lstm_hidden_size = 128
lstm_num_layers = 2
epochs = 30

# Initialize model
set_seed(42)
model = MultimodalModel(lstm_input_size, lstm_hidden_size, lstm_num_layers, clinicalbert)
criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5], device=device))
optimizer = torch.optim.Adam([
    {'params': model.clinicalbert.parameters(), 'lr': 1e-5},
    {'params': [p for n, p in model.named_parameters() if 'clinicalbert' not in n], 'lr': 1e-4}
])

# Move model to device
model.to(device)

epochs = 30
patience = 5  # Number of epochs to wait for improvement
best_val_f1 = 0  # Track best F1-score for early stopping
patience_counter = 0  # Counter for early stopping
counter = 0  # Batch counter for gradient norm printing
best_model_path = "best_model.pth"  # Path to save best model

for epoch in range(epochs):
    # Training phase
    model.train()
    epoch_train_loss = 0

    for batch_idx, batch in enumerate(tqdm(train_dataloader, desc=f"Epoch {epoch+1}/{epochs}")):
        # Check for NaN or Inf values
        if torch.isnan(batch['time_series']).any() or torch.isinf(batch['time_series']).any():
            print(f"Batch {batch_idx}, Warning: NaN or Inf in time_series. Skipping.")
            continue

        # Skip batches with all empty notes
        attention_mask_batch = batch['attention_mask'].to(device, dtype=torch.long)
        non_empty_count = (attention_mask_batch.sum(dim=1) > 1).sum().item()
        if non_empty_count == 0:
            print(f"Batch {batch_idx}, All empty notes, skipping.")
            continue

        # Move data to device
        time_series_batch = batch['time_series'].to(device, dtype=torch.float32)
        input_ids_batch = batch['input_ids'].to(device, dtype=torch.long)
        labels_batch = batch['labels'].to(device, dtype=torch.float32)

        # Forward pass
        outputs = model(time_series_batch, input_ids_batch, attention_mask_batch).squeeze()

        # Ensure numerical stability
        labels_batch = labels_batch.type(torch.float32)
        loss = criterion(outputs, labels_batch)

        # Backward pass with gradient clipping
        optimizer.zero_grad()
        loss.backward()
        if any(torch.isnan(p.grad).any() for p in model.parameters() if p.grad is not None):
            print(f"Batch {batch_idx}, NaN gradients detected")
        for name, param in model.named_parameters():
            if torch.isnan(param).any():
                print(f"Batch {batch_idx}, NaN in {name}")
        # Compute norm before clipping
        if counter % 50 == 0:
            grad_norm = torch.sqrt(sum(p.grad.norm(2)**2 for p in model.parameters() if p.grad is not None))
            print(f"Batch {batch_idx}, Gradient norm before clipping: {grad_norm.item()}")
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)  # Relaxed clipping
        # Compute norm after clipping
        if counter % 50 == 0:
            grad_norm = torch.sqrt(sum(p.grad.norm(2)**2 for p in model.parameters() if p.grad is not None))
            print(f"Batch {batch_idx}, Gradient norm after clipping: {grad_norm.item()}")
        counter += 1
        optimizer.step()

        epoch_train_loss += loss.item()

    avg_train_loss = epoch_train_loss / len(train_dataloader)
    print(f"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}")

    # Validation phase
    model.eval()
    epoch_val_loss = 0
    all_labels = []
    all_probs = []
    all_preds = []

    with torch.no_grad():
        for batch in tqdm(val_dataloader, desc="Validation"):
            # Check for NaN or Inf values
            if torch.isnan(batch['time_series']).any() or torch.isinf(batch['time_series']).any():
                continue

            # Move data to device
            time_series_batch = batch['time_series'].to(device, dtype=torch.float32)
            input_ids_batch = batch['input_ids'].to(device, dtype=torch.long)
            attention_mask_batch = batch['attention_mask'].to(device, dtype=torch.long)
            labels_batch = batch['labels'].to(device, dtype=torch.float32)

            # Forward pass
            outputs = model(time_series_batch, input_ids_batch, attention_mask_batch).squeeze()
            loss = criterion(outputs, labels_batch)

            # Convert logits to probabilities
            probs = torch.sigmoid(outputs)
            preds = (probs > 0.5).float()

            # Collect for metrics
            all_labels.extend(labels_batch.cpu().numpy())
            all_probs.extend(probs.cpu().numpy())
            all_preds.extend(preds.cpu().numpy())

            epoch_val_loss += loss.item()

    avg_val_loss = epoch_val_loss / len(val_dataloader)
    all_labels = np.array(all_labels)
    all_probs = np.array(all_probs)
    all_preds = np.array(all_preds)

    # Compute metrics
    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary', zero_division=0)
    roc_auc = roc_auc_score(all_labels, all_probs) if len(np.unique(all_labels)) > 1 else 0.0
    pr_auc = average_precision_score(all_labels, all_probs) if len(np.unique(all_labels)) > 1 else 0.0

    print(f"Epoch {epoch+1}/{epochs}, Validation Loss: {avg_val_loss:.4f}, "
          f"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, "
          f"ROC AUC: {roc_auc:.4f}, PR AUC: {pr_auc:.4f}")

    # Early stopping
    if f1 > best_val_f1:
        best_val_f1 = f1
        patience_counter = 0
        # Save best model
        torch.save(model.state_dict(), best_model_path)
        print(f"Saved best model with F1: {best_val_f1:.4f}")
    else:
        patience_counter += 1
        print(f"No improvement in F1. Patience counter: {patience_counter}/{patience}")

    if patience_counter >= patience:
        print(f"Early stopping triggered after {epoch+1} epochs.")
        break

# Set model to best model
model.load_state_dict(torch.load(best_model_path))

def evaluate_model(model, dataloader, device, thresholds=np.arange(0.1, 1.0, 0.1), optimize_metric='f1'):
    """
    Evaluate the model on the validation set, tuning the prediction threshold.

    Args:
        model: The PyTorch model (MultimodalModel).
        dataloader: DataLoader for the validation set.
        device: Device to run the model on ('cuda' or 'cpu').
        thresholds: List of thresholds to evaluate (default: 0.1 to 0.9 in steps of 0.1).
        optimize_metric: Metric to optimize ('f1', 'precision', 'recall', 'accuracy').

    Returns:
        dict: Metrics for the default threshold (0.5).
        dict: Best threshold and corresponding metrics.
    """
    model.eval()
    all_labels = []
    all_probs = []

    # Collect predictions and labels
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Evaluating"):
            time_series_batch = batch['time_series'].to(device, dtype=torch.float32)
            input_ids_batch = batch['input_ids'].to(device, dtype=torch.long)
            attention_mask_batch = batch['attention_mask'].to(device, dtype=torch.long)
            labels_batch = batch['labels'].to(device, dtype=torch.float32)

            # Forward pass
            outputs = model(time_series_batch, input_ids_batch, attention_mask_batch).squeeze()
            outputs = torch.sigmoid(outputs)

            # Store labels and probabilities
            all_labels.extend(labels_batch.cpu().numpy())
            all_probs.extend(outputs.cpu().numpy())

    # Convert to arrays
    all_labels = np.array(all_labels)
    all_probs = np.array(all_probs)
    print("Probabilities:", all_probs)

    # Initialize results
    threshold_results = []
    best_threshold = 0.5
    best_score = -1
    default_metrics = {}

    # Evaluate across thresholds
    for threshold in thresholds:
        # Generate predictions
        predictions = (all_probs > threshold).astype(int)
        cm = confusion_matrix(all_labels, predictions)
        TN, FP, FN, TP = cm.ravel()

        # Calculate metrics
        f1 = f1_score(all_labels, predictions)
        acc = accuracy_score(all_labels, predictions)
        precision = TP / (TP + FP) if (TP + FP) > 0 else 0
        recall = TP / (TP + FN) if (TP + FN) > 0 else 0
        cm = confusion_matrix(all_labels, predictions)

        # Store results
        result = {
            'threshold': threshold,
            'f1': f1,
            'accuracy': acc,
            'precision': precision,
            'recall': recall,
            'confusion_matrix': cm
            }
        threshold_results.append(result)

        # Update best threshold
        score = result[optimize_metric]
        if score > best_score:
            best_score = score
            best_threshold = threshold
            best_metrics = result

        # Store default metrics for threshold=0.5
        if abs(threshold - 0.5) < 1e-6:
            default_metrics = result

    # Compute accuracy, f1, confusion_matrix
    default_metrics['accuracy'] = accuracy_score(all_labels, (all_probs > best_threshold).astype(int))
    default_metrics['f1'] = f1_score(all_labels, (all_probs > best_threshold).astype(int))
    default_metrics['confusion_matrix'] = confusion_matrix(all_labels, (all_probs > best_threshold).astype(int))

    # Compute PR and ROC curves
    precision, recall, _ = precision_recall_curve(all_labels, all_probs)
    pr_auc = auc(recall, precision)
    fpr, tpr, _ = roc_curve(all_labels, all_probs)
    roc_auc = auc(fpr, tpr)

    # Update default metrics with AUCs
    default_metrics['pr_auc'] = pr_auc
    default_metrics['roc_auc'] = roc_auc

    # Print default metrics (threshold=0.5)
    print("\nDefault Metrics (Threshold=0.5):")
    print(f"Accuracy: {default_metrics['accuracy']:.4f}")
    print(f"F1-Score: {default_metrics['f1']:.4f}")
    print(f"PR AUC: {default_metrics['pr_auc']:.4f}")
    print(f"ROC AUC: {default_metrics['roc_auc']:.4f}")
    print("\nClassification Report:")
    print(classification_report(all_labels, (all_probs > 0.5).astype(int)))
    print("\nConfusion Matrix:")
    print(default_metrics['confusion_matrix'])

    # Print threshold tuning results
    print("\nThreshold Tuning Results:")
    print(f"{'Threshold':<10} {'F1-Score':<10} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'Confusion Matrix':<20}")
    for result in threshold_results:
        cm_str = f"[[{result['confusion_matrix'][0,0]},{result['confusion_matrix'][0,1]}],[{result['confusion_matrix'][1,0]},{result['confusion_matrix'][1,1]}]]"
        print(f"{result['threshold']:<10.2f} {result['f1']:<10.4f} {result['accuracy']:<10.4f} {result['precision']:<10.4f} {result['recall']:<10.4f} {cm_str:<20}")

    # Print best threshold
    print(f"\nBest Threshold (optimizing {optimize_metric}): {best_threshold:.2f}")
    print(f"Best Metrics: F1={best_metrics['f1']:.4f}, Accuracy={best_metrics['accuracy']:.4f}, Precision={best_metrics['precision']:.4f}, Recall={best_metrics['recall']:.4f}")
    print(f"Best Confusion Matrix:\n{best_metrics['confusion_matrix']}")

    # Plot PR Curve
    plt.figure()
    plt.plot(recall, precision, label=f'PR AUC: {pr_auc:.4f}')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend()
    plt.grid()
    plt.show()

    # Plot ROC Curve
    plt.figure()
    plt.plot(fpr, tpr, label=f'ROC AUC: {roc_auc:.4f}')
    plt.plot([0, 1], [0, 1], linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')
    plt.legend()
    plt.grid()
    plt.show()

    return default_metrics, best_metrics

default_metrics, best_metrics = evaluate_model(model, val_dataloader, device, thresholds=np.arange(0.1, 1.0, 0.02), optimize_metric='f1')

# Final evaluation
optimal_threshold = 0.96
default_metrics, best_metrics = evaluate_model(model, test_dataloader, device, thresholds=[optimal_threshold], optimize_metric='f1')

model.eval()
all_labels = []
all_probs = []

# Collect predictions and labels
with torch.no_grad():
    for batch in tqdm(test_dataloader, desc="Evaluating"):
        time_series_batch = batch['time_series'].to(device, dtype=torch.float32)
        input_ids_batch = batch['input_ids'].to(device, dtype=torch.long)
        attention_mask_batch = batch['attention_mask'].to(device, dtype=torch.long)
        labels_batch = batch['labels'].to(device, dtype=torch.float32)

        # Forward pass
        outputs = model(time_series_batch, input_ids_batch, attention_mask_batch).squeeze()
        outputs = torch.sigmoid(outputs)

        # Store labels and probabilities
        all_labels.extend(labels_batch.cpu().numpy())
        all_probs.extend(outputs.cpu().numpy())

# Convert to arrays
all_labels = np.array(all_labels)
y_pred_proba = np.array(all_probs)
print("Probabilities:", all_probs)

# Compute ROC curve and AUC
fpr, tpr, _ = roc_curve(test_vent_labels, y_pred_proba)
auc_score = roc_auc_score(test_vent_labels, y_pred_proba)
print(f"Deep Learning AUC: {auc_score:.4f}")

